from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field
from typing import List, Dict


class DocumentAnswer(BaseModel):
    text: str = Field(..., description="Answer generated by AI")
    file_name: str = Field(None, description="Original file name")
    page_number: int = Field(None, description="Page number of the chunk")
    score: float = Field(0.0, description="Similarity score or relevance score")


class LLMGenerator:
    """
    LLM Generator for document-based QA using LangChain + OpenAI.
    Returns structured JSON using Pydantic and JsonOutputParser.
    """

    def __init__(self, model_name: str = "gpt-3.5-turbo", temperature: float = 0.0):
        self.model = ChatOpenAI(model_name=model_name, temperature=temperature)
        self.parser = JsonOutputParser(pydantic_object=DocumentAnswer)

        self.prompt_template = PromptTemplate(
            template=(
                "You are an AI assistant. Based on the following document snippets, answer the query:\n\n"
                "Query: {query}\n"
                "Document Snippets:\n{snippets}\n\n"
                "Summarize and answer concisely in JSON format following these instructions:\n"
                "{format_instructions}"
            ),
            input_variables=["query", "snippets"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()}
        )

        # Combine prompt + model + parser into a chain
        self.chain = self.prompt_template | self.model | self.parser

    def generate(self, context: List[Dict], query: str) -> dict:
        """
        Generate AI response.
        Returns: JSON-compliant dict per DocumentAnswer model
        """
        if not query.strip():
            return {
                "error": "Invalid input query",
                "status_code": 400
            }

        if not context or len(context) == 0:
            return {
                "text": "",
                "file_name": None,
                "page_number": None,
                "score": 0.0,
                "message": "No relevant documents found"
            }

        snippets = "\n\n".join(
            [f"{d['text']} (File: {d['file_name']}, Page: {d['page_number']}, Score: {d['score']})"
             for d in context]
        )

        try:
            return self.chain.invoke({"query": query, "snippets": snippets})
        except Exception as e:
            # fallback: return structured error in JSON
            return {
                "text": f"LLM generation failed: {str(e)}",
                "file_name": None,
                "page_number": None,
                "score": 0.0
            }
